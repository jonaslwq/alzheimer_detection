{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "import os\n",
    "import copy\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "import joblib\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train and test DataFrames\n",
    "\n",
    "PREPROCESS_DIR = \"processed_data/glcm/\"\n",
    "X_TRAIN_DIR = PREPROCESS_DIR + \"X_train.pkl\"\n",
    "y_TRAIN_DIR = PREPROCESS_DIR + \"y_train.pkl\"\n",
    "X_TEST_DIR = PREPROCESS_DIR + \"X_test.pkl\"\n",
    "y_TEST_DIR = PREPROCESS_DIR + \"y_test.pkl\"\n",
    "\n",
    "X_train = joblib.load(X_TRAIN_DIR)\n",
    "y_train = pd.read_pickle(y_TRAIN_DIR)\n",
    "X_test = pd.read_pickle(X_TEST_DIR)\n",
    "y_test = pd.read_pickle(y_TEST_DIR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrast_d1_a0</th>\n",
       "      <th>contrast_d1_a0.7853981633974483</th>\n",
       "      <th>contrast_d1_a1.5707963267948966</th>\n",
       "      <th>contrast_d2_a0</th>\n",
       "      <th>contrast_d2_a0.7853981633974483</th>\n",
       "      <th>contrast_d2_a1.5707963267948966</th>\n",
       "      <th>contrast_d3_a0</th>\n",
       "      <th>contrast_d3_a0.7853981633974483</th>\n",
       "      <th>contrast_d3_a1.5707963267948966</th>\n",
       "      <th>dissimilarity_d1_a0</th>\n",
       "      <th>...</th>\n",
       "      <th>y_skew</th>\n",
       "      <th>x_kurtosis</th>\n",
       "      <th>y_kurtosis</th>\n",
       "      <th>glcm_mean</th>\n",
       "      <th>shd_dist1_dir1</th>\n",
       "      <th>shd_dist1_dir2</th>\n",
       "      <th>shd_dist1_dir3</th>\n",
       "      <th>prom_dist1_dir1</th>\n",
       "      <th>prom_dist1_dir2</th>\n",
       "      <th>prom_dist1_dir3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>177.783072</td>\n",
       "      <td>8.223753</td>\n",
       "      <td>0.272827</td>\n",
       "      <td>0.165757</td>\n",
       "      <td>0.968539</td>\n",
       "      <td>0.027475</td>\n",
       "      <td>297.430799</td>\n",
       "      <td>10.748792</td>\n",
       "      <td>0.245486</td>\n",
       "      <td>0.160072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>2.009662</td>\n",
       "      <td>1.896919</td>\n",
       "      <td>18.250708</td>\n",
       "      <td>4.784799e+07</td>\n",
       "      <td>4.946932e+07</td>\n",
       "      <td>4.680497e+07</td>\n",
       "      <td>1.249516e+10</td>\n",
       "      <td>1.287475e+10</td>\n",
       "      <td>1.224099e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>396.158462</td>\n",
       "      <td>12.603802</td>\n",
       "      <td>0.230600</td>\n",
       "      <td>0.157574</td>\n",
       "      <td>0.967524</td>\n",
       "      <td>0.024830</td>\n",
       "      <td>655.041704</td>\n",
       "      <td>16.629786</td>\n",
       "      <td>0.213508</td>\n",
       "      <td>0.154089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074640</td>\n",
       "      <td>1.975310</td>\n",
       "      <td>1.932083</td>\n",
       "      <td>19.071022</td>\n",
       "      <td>1.668901e+08</td>\n",
       "      <td>1.704196e+08</td>\n",
       "      <td>1.625122e+08</td>\n",
       "      <td>6.384172e+10</td>\n",
       "      <td>6.498358e+10</td>\n",
       "      <td>6.216693e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>345.529028</td>\n",
       "      <td>12.307171</td>\n",
       "      <td>0.238930</td>\n",
       "      <td>0.165130</td>\n",
       "      <td>0.968250</td>\n",
       "      <td>0.027268</td>\n",
       "      <td>545.579795</td>\n",
       "      <td>15.410374</td>\n",
       "      <td>0.219580</td>\n",
       "      <td>0.158783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>1.999626</td>\n",
       "      <td>1.953345</td>\n",
       "      <td>18.321593</td>\n",
       "      <td>1.272682e+08</td>\n",
       "      <td>1.322923e+08</td>\n",
       "      <td>1.245953e+08</td>\n",
       "      <td>4.631719e+10</td>\n",
       "      <td>4.800118e+10</td>\n",
       "      <td>4.539574e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>287.623451</td>\n",
       "      <td>9.922127</td>\n",
       "      <td>0.255265</td>\n",
       "      <td>0.160253</td>\n",
       "      <td>0.962538</td>\n",
       "      <td>0.025681</td>\n",
       "      <td>436.259231</td>\n",
       "      <td>12.855893</td>\n",
       "      <td>0.229888</td>\n",
       "      <td>0.154968</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055772</td>\n",
       "      <td>2.013545</td>\n",
       "      <td>1.962250</td>\n",
       "      <td>18.906336</td>\n",
       "      <td>8.524542e+07</td>\n",
       "      <td>8.810263e+07</td>\n",
       "      <td>8.418482e+07</td>\n",
       "      <td>2.595670e+10</td>\n",
       "      <td>2.674941e+10</td>\n",
       "      <td>2.566126e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312.000638</td>\n",
       "      <td>11.654327</td>\n",
       "      <td>0.236421</td>\n",
       "      <td>0.158486</td>\n",
       "      <td>0.975516</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>589.377907</td>\n",
       "      <td>15.842767</td>\n",
       "      <td>0.215629</td>\n",
       "      <td>0.152594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040579</td>\n",
       "      <td>1.955352</td>\n",
       "      <td>1.900882</td>\n",
       "      <td>19.078750</td>\n",
       "      <td>1.712434e+08</td>\n",
       "      <td>1.776251e+08</td>\n",
       "      <td>1.670757e+08</td>\n",
       "      <td>6.694403e+10</td>\n",
       "      <td>6.923703e+10</td>\n",
       "      <td>6.534362e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>296.518162</td>\n",
       "      <td>10.862258</td>\n",
       "      <td>0.236017</td>\n",
       "      <td>0.152198</td>\n",
       "      <td>0.975313</td>\n",
       "      <td>0.023164</td>\n",
       "      <td>555.103917</td>\n",
       "      <td>15.319699</td>\n",
       "      <td>0.209712</td>\n",
       "      <td>0.147373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057822</td>\n",
       "      <td>1.968125</td>\n",
       "      <td>1.932727</td>\n",
       "      <td>19.824304</td>\n",
       "      <td>1.885681e+08</td>\n",
       "      <td>1.945525e+08</td>\n",
       "      <td>1.835131e+08</td>\n",
       "      <td>7.227613e+10</td>\n",
       "      <td>7.431489e+10</td>\n",
       "      <td>7.028847e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4125</th>\n",
       "      <td>342.557965</td>\n",
       "      <td>12.203049</td>\n",
       "      <td>0.228426</td>\n",
       "      <td>0.153617</td>\n",
       "      <td>0.972161</td>\n",
       "      <td>0.023598</td>\n",
       "      <td>609.839934</td>\n",
       "      <td>16.129141</td>\n",
       "      <td>0.212036</td>\n",
       "      <td>0.148591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131674</td>\n",
       "      <td>1.971660</td>\n",
       "      <td>1.917816</td>\n",
       "      <td>19.655057</td>\n",
       "      <td>1.741305e+08</td>\n",
       "      <td>1.797563e+08</td>\n",
       "      <td>1.697855e+08</td>\n",
       "      <td>6.695057e+10</td>\n",
       "      <td>6.889975e+10</td>\n",
       "      <td>6.528664e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4126</th>\n",
       "      <td>355.140447</td>\n",
       "      <td>11.792915</td>\n",
       "      <td>0.237928</td>\n",
       "      <td>0.152600</td>\n",
       "      <td>0.970891</td>\n",
       "      <td>0.023287</td>\n",
       "      <td>633.553276</td>\n",
       "      <td>16.275083</td>\n",
       "      <td>0.215313</td>\n",
       "      <td>0.147693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060607</td>\n",
       "      <td>1.954471</td>\n",
       "      <td>1.894453</td>\n",
       "      <td>19.795361</td>\n",
       "      <td>1.695321e+08</td>\n",
       "      <td>1.748043e+08</td>\n",
       "      <td>1.655580e+08</td>\n",
       "      <td>6.526340e+10</td>\n",
       "      <td>6.703786e+10</td>\n",
       "      <td>6.368383e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>378.671275</td>\n",
       "      <td>12.567797</td>\n",
       "      <td>0.224769</td>\n",
       "      <td>0.150808</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.022743</td>\n",
       "      <td>677.637930</td>\n",
       "      <td>17.019954</td>\n",
       "      <td>0.204249</td>\n",
       "      <td>0.147461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062477</td>\n",
       "      <td>1.961901</td>\n",
       "      <td>1.860322</td>\n",
       "      <td>19.921335</td>\n",
       "      <td>1.796878e+08</td>\n",
       "      <td>1.832785e+08</td>\n",
       "      <td>1.745383e+08</td>\n",
       "      <td>6.895293e+10</td>\n",
       "      <td>7.005235e+10</td>\n",
       "      <td>6.697519e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128</th>\n",
       "      <td>363.747445</td>\n",
       "      <td>12.163761</td>\n",
       "      <td>0.224360</td>\n",
       "      <td>0.152212</td>\n",
       "      <td>0.968307</td>\n",
       "      <td>0.023169</td>\n",
       "      <td>643.368246</td>\n",
       "      <td>16.629940</td>\n",
       "      <td>0.206180</td>\n",
       "      <td>0.148534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005187</td>\n",
       "      <td>1.914427</td>\n",
       "      <td>1.925837</td>\n",
       "      <td>19.761571</td>\n",
       "      <td>1.634114e+08</td>\n",
       "      <td>1.670027e+08</td>\n",
       "      <td>1.590929e+08</td>\n",
       "      <td>6.134182e+10</td>\n",
       "      <td>6.245482e+10</td>\n",
       "      <td>5.971834e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4129 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      contrast_d1_a0  contrast_d1_a0.7853981633974483  \\\n",
       "0         177.783072                         8.223753   \n",
       "1         396.158462                        12.603802   \n",
       "2         345.529028                        12.307171   \n",
       "3         287.623451                         9.922127   \n",
       "4         312.000638                        11.654327   \n",
       "...              ...                              ...   \n",
       "4124      296.518162                        10.862258   \n",
       "4125      342.557965                        12.203049   \n",
       "4126      355.140447                        11.792915   \n",
       "4127      378.671275                        12.567797   \n",
       "4128      363.747445                        12.163761   \n",
       "\n",
       "      contrast_d1_a1.5707963267948966  contrast_d2_a0  \\\n",
       "0                            0.272827        0.165757   \n",
       "1                            0.230600        0.157574   \n",
       "2                            0.238930        0.165130   \n",
       "3                            0.255265        0.160253   \n",
       "4                            0.236421        0.158486   \n",
       "...                               ...             ...   \n",
       "4124                         0.236017        0.152198   \n",
       "4125                         0.228426        0.153617   \n",
       "4126                         0.237928        0.152600   \n",
       "4127                         0.224769        0.150808   \n",
       "4128                         0.224360        0.152212   \n",
       "\n",
       "      contrast_d2_a0.7853981633974483  contrast_d2_a1.5707963267948966  \\\n",
       "0                            0.968539                         0.027475   \n",
       "1                            0.967524                         0.024830   \n",
       "2                            0.968250                         0.027268   \n",
       "3                            0.962538                         0.025681   \n",
       "4                            0.975516                         0.025118   \n",
       "...                               ...                              ...   \n",
       "4124                         0.975313                         0.023164   \n",
       "4125                         0.972161                         0.023598   \n",
       "4126                         0.970891                         0.023287   \n",
       "4127                         0.968889                         0.022743   \n",
       "4128                         0.968307                         0.023169   \n",
       "\n",
       "      contrast_d3_a0  contrast_d3_a0.7853981633974483  \\\n",
       "0         297.430799                        10.748792   \n",
       "1         655.041704                        16.629786   \n",
       "2         545.579795                        15.410374   \n",
       "3         436.259231                        12.855893   \n",
       "4         589.377907                        15.842767   \n",
       "...              ...                              ...   \n",
       "4124      555.103917                        15.319699   \n",
       "4125      609.839934                        16.129141   \n",
       "4126      633.553276                        16.275083   \n",
       "4127      677.637930                        17.019954   \n",
       "4128      643.368246                        16.629940   \n",
       "\n",
       "      contrast_d3_a1.5707963267948966  dissimilarity_d1_a0  ...    y_skew  \\\n",
       "0                            0.245486             0.160072  ...  0.007194   \n",
       "1                            0.213508             0.154089  ...  0.074640   \n",
       "2                            0.219580             0.158783  ... -0.000063   \n",
       "3                            0.229888             0.154968  ... -0.055772   \n",
       "4                            0.215629             0.152594  ...  0.040579   \n",
       "...                               ...                  ...  ...       ...   \n",
       "4124                         0.209712             0.147373  ...  0.057822   \n",
       "4125                         0.212036             0.148591  ...  0.131674   \n",
       "4126                         0.215313             0.147693  ...  0.060607   \n",
       "4127                         0.204249             0.147461  ...  0.062477   \n",
       "4128                         0.206180             0.148534  ... -0.005187   \n",
       "\n",
       "      x_kurtosis  y_kurtosis  glcm_mean  shd_dist1_dir1  shd_dist1_dir2  \\\n",
       "0       2.009662    1.896919  18.250708    4.784799e+07    4.946932e+07   \n",
       "1       1.975310    1.932083  19.071022    1.668901e+08    1.704196e+08   \n",
       "2       1.999626    1.953345  18.321593    1.272682e+08    1.322923e+08   \n",
       "3       2.013545    1.962250  18.906336    8.524542e+07    8.810263e+07   \n",
       "4       1.955352    1.900882  19.078750    1.712434e+08    1.776251e+08   \n",
       "...          ...         ...        ...             ...             ...   \n",
       "4124    1.968125    1.932727  19.824304    1.885681e+08    1.945525e+08   \n",
       "4125    1.971660    1.917816  19.655057    1.741305e+08    1.797563e+08   \n",
       "4126    1.954471    1.894453  19.795361    1.695321e+08    1.748043e+08   \n",
       "4127    1.961901    1.860322  19.921335    1.796878e+08    1.832785e+08   \n",
       "4128    1.914427    1.925837  19.761571    1.634114e+08    1.670027e+08   \n",
       "\n",
       "      shd_dist1_dir3  prom_dist1_dir1  prom_dist1_dir2  prom_dist1_dir3  \n",
       "0       4.680497e+07     1.249516e+10     1.287475e+10     1.224099e+10  \n",
       "1       1.625122e+08     6.384172e+10     6.498358e+10     6.216693e+10  \n",
       "2       1.245953e+08     4.631719e+10     4.800118e+10     4.539574e+10  \n",
       "3       8.418482e+07     2.595670e+10     2.674941e+10     2.566126e+10  \n",
       "4       1.670757e+08     6.694403e+10     6.923703e+10     6.534362e+10  \n",
       "...              ...              ...              ...              ...  \n",
       "4124    1.835131e+08     7.227613e+10     7.431489e+10     7.028847e+10  \n",
       "4125    1.697855e+08     6.695057e+10     6.889975e+10     6.528664e+10  \n",
       "4126    1.655580e+08     6.526340e+10     6.703786e+10     6.368383e+10  \n",
       "4127    1.745383e+08     6.895293e+10     7.005235e+10     6.697519e+10  \n",
       "4128    1.590929e+08     6.134182e+10     6.245482e+10     5.971834e+10  \n",
       "\n",
       "[4129 rows x 67 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection // Removing highly correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old\n",
      "(1030, 67)\n",
      "(4129, 67)\n"
     ]
    }
   ],
   "source": [
    "# # If feature selection\n",
    "# FEATURE_SELECTION = \"processed_data/ft/\"\n",
    "# FT_FILE = \"xgb_ft_jiaxu.pkl\"\n",
    "\n",
    "# import joblib\n",
    "\n",
    "# CURRENT_DIRECTORY = os.getcwd()\n",
    "# FEATURE_SORTED = joblib.load(FEATURE_SELECTION + FT_FILE)\n",
    "# NUM_FEAT = 30\n",
    "# FEATURES = FEATURE_SORTED[:NUM_FEAT]\n",
    "# print(FEATURES)\n",
    "\n",
    "# X_train = X_train[FEATURES]\n",
    "# X_test = X_test[FEATURES]\n",
    "\n",
    "print(\"Old\")\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_corr_cols = joblib.load(\"processed_data\\\\ft\\\\low_corr_cols.pkl\")\n",
    "\n",
    "# X_train = X_train[low_corr_cols]\n",
    "# X_test = X_test[low_corr_cols]\n",
    "\n",
    "# print(\"After Removing Correlated Columns\")\n",
    "# print(X_test.shape)\n",
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 2049, 1: 1433, 2: 605, 3: 42})\n",
      "Resampled dataset shape Counter({2: 2049, 3: 2049, 0: 2049, 1: 2049})\n"
     ]
    }
   ],
   "source": [
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Original dataset shape %s' % Counter(y_train))\n",
    "# sme = SMOTEENN(random_state=42)\n",
    "# X_train, y_train = sme.fit_resample(X_train, y_train)\n",
    "\n",
    "# print('Resampled dataset shape %s' % Counter(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'y_train': y_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "Models available: Plain_rf, Rf_op, Plain_xgb, xgb_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2_score(y_true, y_pred, beta=2):\n",
    "    precision = precision_score(y_true, y_pred, average = \"weighted\")\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    \n",
    "    f2 = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "    \n",
    "    return f2\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    results = {\n",
    "        'recall': recall_score(y_test, y_pred, average = 'weighted'),\n",
    "        'precision': precision_score(y_test, y_pred, average = 'weighted'),\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred, average = 'weighted'),\n",
    "        'mcc': matthews_corrcoef(y_test, y_pred),\n",
    "        'f2_score': f2_score(y_test, y_pred)\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def plain_rf(X_train, y_train, X_test, y_test, metric = \"recall\"):\n",
    "    \n",
    "    rf_model = RandomForestClassifier()\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    pred = rf_model.predict(X_test)\n",
    "\n",
    "    results = evaluate(y_test, pred)\n",
    "\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "    plot_cl(y_test, pred)\n",
    "\n",
    "    return pred, results[metric]\n",
    "\n",
    "def rf_op(X_train, y_train, X_test, y_test, metric = \"recall\"):\n",
    "\n",
    "    def rf_trial(trial, final = False):\n",
    "        param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        # 'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt']),\n",
    "        # 'class_weight': trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample', None]),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "        }\n",
    "\n",
    "        model = RandomForestClassifier(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        result = evaluate(y_test, preds)\n",
    "\n",
    "        if final:\n",
    "            print(classification_report(y_test, preds))\n",
    "            plot_cl(y_test, preds)\n",
    "\n",
    "            return preds, result[metric]\n",
    "        \n",
    "\n",
    "    study = optuna.create_study(direction = \"maximize\")\n",
    "    study.optimize(rf_trial, n_trials = 100)\n",
    "\n",
    "    model = study.best_trial\n",
    "    model_copy = copy.deepcopy(model)\n",
    "\n",
    "    pred, results = rf_trial(model_copy, final = True)\n",
    "\n",
    "    return pred, results\n",
    "\n",
    "def plain_xgb(X_train, y_train, X_test, y_test, metric = \"recall\"):\n",
    "    \"\"\"\n",
    "    Perform XGBoost multiclass classification, evaluate the model, and create a confusion matrix.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (torch.Tensor): Training features.\n",
    "    y_train (torch.Tensor): Training labels.\n",
    "    X_test (torch.Tensor): Testing features.\n",
    "    y_test (torch.Tensor): Testing labels.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "    plot_cl(y_test, pred)\n",
    "\n",
    "    results = evaluate(y_test, pred)\n",
    "\n",
    "    return pred, results[metric]\n",
    "    \n",
    "    \n",
    "def xgb_op(X_train, X_test, y_train, y_test, metric = 'accuracy'):\n",
    "    \n",
    "\n",
    "    def xgb_trial(trial, final = False):\n",
    "\n",
    "        param = {\n",
    "        'objective': 'multi:softmax',  # For multiclass classification\n",
    "        'num_class': len(set(y_train)),  # Number of classes\n",
    "        'eval_metric': 'mlogloss',  # Multiclass log loss\n",
    "        'tree_method': 'hist',  # Faster training method\n",
    "        'booster': 'gbtree',\n",
    "        'verbosity': 0,\n",
    "        'n_jobs': -1,\n",
    "        'use_label_encoder': False,\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-5, 1e3),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 1e1),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 1e1),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 1),\n",
    "        'n_estimators': 100\n",
    "        }\n",
    "\n",
    "        model = xgb.XGBClassifier(**param)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        results = evaluate(y_test, pred)\n",
    "\n",
    "        if final:\n",
    "            print(classification_report(y_test, pred))\n",
    "            plot_cl(y_test, pred)\n",
    "\n",
    "            return pred, results[metric]\n",
    "\n",
    "        return results[metric]\n",
    "\n",
    "    study = optuna.create_study(direction = \"maximize\")\n",
    "    study.optimize(xgb_trial, n_trials = 100)\n",
    "\n",
    "    model = study.best_trial\n",
    "    model_copy = copy.deepcopy(model)\n",
    "\n",
    "    pred, results = xgb_trial(model_copy, final = True)\n",
    "\n",
    "    return pred, results\n",
    "\n",
    "\n",
    "def plot_cl(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Plot confusion matrix as a heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels= set(y_test), yticklabels=set(y_test))\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "def roc_curve(y_test, y_pred):\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "    # Calculate the Area Under the ROC Curve (AUC)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-11 16:04:37,491] A new study created in memory with name: no-name-661c3516-802f-4d80-bc29-7faf326ca694\n",
      "[I 2023-11-11 16:04:38,273] Trial 0 finished with value: 0.5349514563106796 and parameters: {'max_depth': 3, 'min_child_weight': 434.40300289119125, 'subsample': 0.9635987851018164, 'colsample_bytree': 0.7381156609285793, 'reg_alpha': 4.555444622877283, 'reg_lambda': 0.05153085854472149, 'learning_rate': 0.00354377174480032}. Best is trial 0 with value: 0.5349514563106796.\n",
      "[I 2023-11-11 16:04:39,894] Trial 1 finished with value: 0.6097087378640776 and parameters: {'max_depth': 5, 'min_child_weight': 0.03398736749894668, 'subsample': 0.5514742964315136, 'colsample_bytree': 0.8960048365867396, 'reg_alpha': 0.6292061717338402, 'reg_lambda': 4.995543843514994, 'learning_rate': 0.003331423596120727}. Best is trial 1 with value: 0.6097087378640776.\n",
      "[I 2023-11-11 16:04:42,923] Trial 2 finished with value: 0.7533980582524272 and parameters: {'max_depth': 7, 'min_child_weight': 0.790779443070921, 'subsample': 0.5289729128147458, 'colsample_bytree': 0.8538234899511595, 'reg_alpha': 4.452598690124459e-05, 'reg_lambda': 2.85627381273282e-05, 'learning_rate': 0.14736636459254523}. Best is trial 2 with value: 0.7533980582524272.\n",
      "[I 2023-11-11 16:04:48,678] Trial 3 finished with value: 0.7165048543689321 and parameters: {'max_depth': 9, 'min_child_weight': 1.9386799813031333e-05, 'subsample': 0.7877220448509239, 'colsample_bytree': 0.7225540387999914, 'reg_alpha': 3.9228541508484217e-05, 'reg_lambda': 0.1702742540635243, 'learning_rate': 0.0028658978452884964}. Best is trial 2 with value: 0.7533980582524272.\n",
      "[I 2023-11-11 16:04:57,822] Trial 4 finished with value: 0.7728155339805826 and parameters: {'max_depth': 10, 'min_child_weight': 0.00689406347170278, 'subsample': 0.6498356889068295, 'colsample_bytree': 0.7883369219454472, 'reg_alpha': 0.0005557619994650938, 'reg_lambda': 0.00018846104108717938, 'learning_rate': 0.11889935848999575}. Best is trial 4 with value: 0.7728155339805826.\n",
      "[I 2023-11-11 16:04:58,984] Trial 5 finished with value: 0.5563106796116505 and parameters: {'max_depth': 6, 'min_child_weight': 112.53704730872894, 'subsample': 0.5958491456193991, 'colsample_bytree': 0.7583687810990446, 'reg_alpha': 0.27374626323229834, 'reg_lambda': 0.0004774479516944567, 'learning_rate': 0.0025957369413271854}. Best is trial 4 with value: 0.7728155339805826.\n",
      "[I 2023-11-11 16:05:02,048] Trial 6 finished with value: 0.6805825242718446 and parameters: {'max_depth': 7, 'min_child_weight': 4.959640544406628, 'subsample': 0.9105814212904109, 'colsample_bytree': 0.777064222628074, 'reg_alpha': 1.9452852713422941, 'reg_lambda': 2.1782583651602807, 'learning_rate': 0.031112991094329998}. Best is trial 4 with value: 0.7728155339805826.\n",
      "[I 2023-11-11 16:05:05,165] Trial 7 finished with value: 0.6883495145631068 and parameters: {'max_depth': 6, 'min_child_weight': 2.107441842015041, 'subsample': 0.6355708627420279, 'colsample_bytree': 0.9541233122907182, 'reg_alpha': 0.005547692467208648, 'reg_lambda': 0.009426575710111402, 'learning_rate': 0.033186030672252106}. Best is trial 4 with value: 0.7728155339805826.\n",
      "[I 2023-11-11 16:05:11,898] Trial 8 finished with value: 0.7300970873786408 and parameters: {'max_depth': 9, 'min_child_weight': 0.8601507612514777, 'subsample': 0.7215573540768527, 'colsample_bytree': 0.6517375757323731, 'reg_alpha': 0.3072949466557525, 'reg_lambda': 0.0007574446233374349, 'learning_rate': 0.020354010558938124}. Best is trial 4 with value: 0.7728155339805826.\n",
      "[I 2023-11-11 16:05:18,663] Trial 9 finished with value: 0.6912621359223301 and parameters: {'max_depth': 7, 'min_child_weight': 0.04707432397722962, 'subsample': 0.6871625648287238, 'colsample_bytree': 0.9155545120131575, 'reg_alpha': 1.0724381695543102e-05, 'reg_lambda': 0.000437615995224068, 'learning_rate': 0.011724528927667687}. Best is trial 4 with value: 0.7728155339805826.\n",
      "[I 2023-11-11 16:05:21,199] Trial 10 finished with value: 0.5786407766990291 and parameters: {'max_depth': 10, 'min_child_weight': 0.0011724073119450066, 'subsample': 0.8088961869953091, 'colsample_bytree': 0.5510984823802207, 'reg_alpha': 0.0007385231125041459, 'reg_lambda': 2.3452353802028983e-05, 'learning_rate': 0.9836210852371282}. Best is trial 4 with value: 0.7728155339805826.\n",
      "[I 2023-11-11 16:05:28,295] Trial 11 finished with value: 0.7621359223300971 and parameters: {'max_depth': 8, 'min_child_weight': 0.0033127094050680577, 'subsample': 0.515651249455479, 'colsample_bytree': 0.839555942348057, 'reg_alpha': 0.00015044827268917297, 'reg_lambda': 1.576623358582294e-05, 'learning_rate': 0.16130998448809547}. Best is trial 4 with value: 0.7728155339805826.\n",
      "[I 2023-11-11 16:05:39,859] Trial 12 finished with value: 0.7708737864077669 and parameters: {'max_depth': 10, 'min_child_weight': 0.001206864739979716, 'subsample': 0.5412920744639818, 'colsample_bytree': 0.8356412190282932, 'reg_alpha': 0.0005334707271679188, 'reg_lambda': 1.0860287575791743e-05, 'learning_rate': 0.15994097164397894}. Best is trial 4 with value: 0.7728155339805826.\n",
      "[I 2023-11-11 16:05:51,809] Trial 13 finished with value: 0.7796116504854369 and parameters: {'max_depth': 10, 'min_child_weight': 0.0003091742687211315, 'subsample': 0.6434249894840619, 'colsample_bytree': 0.8424962963132024, 'reg_alpha': 0.001265204117661855, 'reg_lambda': 0.00013265660849779014, 'learning_rate': 0.13393315189819965}. Best is trial 13 with value: 0.7796116504854369.\n",
      "[I 2023-11-11 16:06:01,391] Trial 14 finished with value: 0.7640776699029126 and parameters: {'max_depth': 9, 'min_child_weight': 5.172181312986876e-05, 'subsample': 0.6484987438052474, 'colsample_bytree': 0.9868620921704004, 'reg_alpha': 0.007034853619846695, 'reg_lambda': 0.00013114241116547298, 'learning_rate': 0.08536236029719979}. Best is trial 13 with value: 0.7796116504854369.\n",
      "[I 2023-11-11 16:06:09,424] Trial 15 finished with value: 0.7796116504854369 and parameters: {'max_depth': 10, 'min_child_weight': 0.0001602083131302242, 'subsample': 0.6099816268826772, 'colsample_bytree': 0.8095754586148441, 'reg_alpha': 0.0014555672137218925, 'reg_lambda': 0.00244335883322447, 'learning_rate': 0.566910984239244}. Best is trial 13 with value: 0.7796116504854369.\n",
      "[I 2023-11-11 16:06:11,989] Trial 16 finished with value: 0.6902912621359223 and parameters: {'max_depth': 4, 'min_child_weight': 0.00015804123065078695, 'subsample': 0.5938102095221732, 'colsample_bytree': 0.9992258823214004, 'reg_alpha': 0.024900687415377813, 'reg_lambda': 0.0029228397800908114, 'learning_rate': 0.7654896368589594}. Best is trial 13 with value: 0.7796116504854369.\n",
      "[I 2023-11-11 16:06:18,939] Trial 17 finished with value: 0.7922330097087379 and parameters: {'max_depth': 8, 'min_child_weight': 1.233078229809648e-05, 'subsample': 0.7240933065447783, 'colsample_bytree': 0.9093661340357126, 'reg_alpha': 0.029860073753088804, 'reg_lambda': 0.0029124036025244856, 'learning_rate': 0.43584694269391044}. Best is trial 17 with value: 0.7922330097087379.\n",
      "[I 2023-11-11 16:06:26,038] Trial 18 finished with value: 0.7757281553398059 and parameters: {'max_depth': 8, 'min_child_weight': 1.1843035782828476e-05, 'subsample': 0.7235991163849373, 'colsample_bytree': 0.89762420242116, 'reg_alpha': 0.03667826266741566, 'reg_lambda': 9.834367850449258e-05, 'learning_rate': 0.3462069476061031}. Best is trial 17 with value: 0.7922330097087379.\n",
      "[I 2023-11-11 16:06:33,212] Trial 19 finished with value: 0.7912621359223301 and parameters: {'max_depth': 8, 'min_child_weight': 0.00022912959127211228, 'subsample': 0.7628023151818746, 'colsample_bytree': 0.9358272720404226, 'reg_alpha': 0.04280288097026514, 'reg_lambda': 0.0016329500305689482, 'learning_rate': 0.3600484877051938}. Best is trial 17 with value: 0.7922330097087379.\n",
      "[I 2023-11-11 16:06:39,253] Trial 20 finished with value: 0.7737864077669903 and parameters: {'max_depth': 8, 'min_child_weight': 1.0662636760029513e-05, 'subsample': 0.7946606041368932, 'colsample_bytree': 0.940378528907282, 'reg_alpha': 0.08641309952314428, 'reg_lambda': 0.017727739471828586, 'learning_rate': 0.42158103535828073}. Best is trial 17 with value: 0.7922330097087379.\n",
      "[I 2023-11-11 16:06:46,587] Trial 21 finished with value: 0.7951456310679612 and parameters: {'max_depth': 8, 'min_child_weight': 0.00016255808112822692, 'subsample': 0.7580973439825934, 'colsample_bytree': 0.8783512603202381, 'reg_alpha': 0.003976903774960089, 'reg_lambda': 0.0019099584315246444, 'learning_rate': 0.2791277873908172}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:06:53,770] Trial 22 finished with value: 0.7815533980582524 and parameters: {'max_depth': 8, 'min_child_weight': 7.510941943596295e-05, 'subsample': 0.769347782724652, 'colsample_bytree': 0.8878198951838654, 'reg_alpha': 0.013827703778460593, 'reg_lambda': 0.0017023079609610346, 'learning_rate': 0.32642802598338316}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:06:57,933] Trial 23 finished with value: 0.7533980582524272 and parameters: {'max_depth': 9, 'min_child_weight': 4.8467346240107916e-05, 'subsample': 0.8524875497331266, 'colsample_bytree': 0.9475459763313313, 'reg_alpha': 0.06622960674772957, 'reg_lambda': 0.004889810417086134, 'learning_rate': 0.9645758778810118}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:07:04,072] Trial 24 finished with value: 0.7786407766990291 and parameters: {'max_depth': 7, 'min_child_weight': 0.00043882821291616137, 'subsample': 0.7449091766278833, 'colsample_bytree': 0.8821595390975973, 'reg_alpha': 0.004442908509388066, 'reg_lambda': 0.0011281437444135628, 'learning_rate': 0.44687988981645443}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:07:11,847] Trial 25 finished with value: 0.7776699029126214 and parameters: {'max_depth': 8, 'min_child_weight': 4.30923421875643e-05, 'subsample': 0.6925751461510009, 'colsample_bytree': 0.9337351147800114, 'reg_alpha': 0.014087028395311865, 'reg_lambda': 0.007065153087102549, 'learning_rate': 0.25576558513604386}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:07:15,782] Trial 26 finished with value: 0.7776699029126214 and parameters: {'max_depth': 6, 'min_child_weight': 0.00039906378684403026, 'subsample': 0.8480304685401462, 'colsample_bytree': 0.9667552314093527, 'reg_alpha': 0.10298667002189549, 'reg_lambda': 0.021369054485870217, 'learning_rate': 0.25428484148299035}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:07:18,514] Trial 27 finished with value: 0.7475728155339806 and parameters: {'max_depth': 5, 'min_child_weight': 1.0603325383700788e-05, 'subsample': 0.7477786616430431, 'colsample_bytree': 0.9142409314540707, 'reg_alpha': 0.0026539185577418647, 'reg_lambda': 0.0018103161566504788, 'learning_rate': 0.6192729207568796}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:07:27,519] Trial 28 finished with value: 0.7786407766990291 and parameters: {'max_depth': 9, 'min_child_weight': 0.003937373860809927, 'subsample': 0.7018755838399875, 'colsample_bytree': 0.974516568508501, 'reg_alpha': 0.0232673581307146, 'reg_lambda': 0.004567084796500116, 'learning_rate': 0.08213348575409572}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:07:28,796] Trial 29 finished with value: 0.7097087378640776 and parameters: {'max_depth': 3, 'min_child_weight': 9.491960345349416e-05, 'subsample': 0.8295495168152294, 'colsample_bytree': 0.8716530116352099, 'reg_alpha': 0.010134854153875302, 'reg_lambda': 0.024811192877381694, 'learning_rate': 0.6059476440250213}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:07:36,962] Trial 30 finished with value: 0.7815533980582524 and parameters: {'max_depth': 8, 'min_child_weight': 0.0009034656180783914, 'subsample': 0.7712361016441163, 'colsample_bytree': 0.9212943025899921, 'reg_alpha': 0.003060010261902227, 'reg_lambda': 0.07514327384017501, 'learning_rate': 0.2382241187694891}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:07:44,385] Trial 31 finished with value: 0.7844660194174757 and parameters: {'max_depth': 8, 'min_child_weight': 7.16671283384221e-05, 'subsample': 0.7623673920405566, 'colsample_bytree': 0.8717264348464416, 'reg_alpha': 0.016059699882298942, 'reg_lambda': 0.0013905722843677035, 'learning_rate': 0.349080146195971}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:07:49,857] Trial 32 finished with value: 0.7834951456310679 and parameters: {'max_depth': 7, 'min_child_weight': 2.7100062670332084e-05, 'subsample': 0.7513042659127294, 'colsample_bytree': 0.8690039614673739, 'reg_alpha': 0.04585776101940632, 'reg_lambda': 0.0011397781446624324, 'learning_rate': 0.4740315633693723}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:07:57,003] Trial 33 finished with value: 0.7873786407766991 and parameters: {'max_depth': 8, 'min_child_weight': 0.00016458084543757905, 'subsample': 0.822968366187916, 'colsample_bytree': 0.9063656426162002, 'reg_alpha': 0.015098962990683931, 'reg_lambda': 0.00047457348232146125, 'learning_rate': 0.25649183769058864}. Best is trial 21 with value: 0.7951456310679612.\n",
      "[I 2023-11-11 16:08:05,756] Trial 34 finished with value: 0.7980582524271844 and parameters: {'max_depth': 9, 'min_child_weight': 0.012739521372570398, 'subsample': 0.8028160580642549, 'colsample_bytree': 0.9180254129249213, 'reg_alpha': 0.14599868910829936, 'reg_lambda': 0.000415776110245351, 'learning_rate': 0.23159096925253903}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:08:10,810] Trial 35 finished with value: 0.7747572815533981 and parameters: {'max_depth': 9, 'min_child_weight': 0.015026840409611348, 'subsample': 0.7833009870245633, 'colsample_bytree': 0.9622516511200471, 'reg_alpha': 0.11762766905318242, 'reg_lambda': 0.0032861905565993153, 'learning_rate': 0.6596563218138675}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:08:15,592] Trial 36 finished with value: 0.7281553398058253 and parameters: {'max_depth': 9, 'min_child_weight': 0.09647554156731807, 'subsample': 0.8050921462030992, 'colsample_bytree': 0.9328176950450295, 'reg_alpha': 9.636509072573363, 'reg_lambda': 0.012113825086422284, 'learning_rate': 0.18992688706397287}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:08:21,523] Trial 37 finished with value: 0.7572815533980582 and parameters: {'max_depth': 7, 'min_child_weight': 0.016450201327991784, 'subsample': 0.8989914401790859, 'colsample_bytree': 0.8137490959996433, 'reg_alpha': 0.6878870205015134, 'reg_lambda': 5.507124600677824e-05, 'learning_rate': 0.10269523292591419}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:08:30,689] Trial 38 finished with value: 0.7058252427184466 and parameters: {'max_depth': 9, 'min_child_weight': 0.0017843377062445388, 'subsample': 0.7210352194411176, 'colsample_bytree': 0.9985820367590267, 'reg_alpha': 0.044328244735402415, 'reg_lambda': 0.00045556257030631055, 'learning_rate': 0.0010275493764778832}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:08:35,492] Trial 39 finished with value: 0.7378640776699029 and parameters: {'max_depth': 7, 'min_child_weight': 2.480746445389319e-05, 'subsample': 0.674677838669138, 'colsample_bytree': 0.9059257939084687, 'reg_alpha': 0.2292525144503677, 'reg_lambda': 0.00024377280522989614, 'learning_rate': 0.06404340984166525}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:08:39,503] Trial 40 finished with value: 0.7650485436893204 and parameters: {'max_depth': 6, 'min_child_weight': 0.006690494324713935, 'subsample': 0.7317353658863096, 'colsample_bytree': 0.9530621447038805, 'reg_alpha': 1.2558360690202186, 'reg_lambda': 0.00023515649520912293, 'learning_rate': 0.20371016765620703}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:08:46,236] Trial 41 finished with value: 0.7786407766990291 and parameters: {'max_depth': 8, 'min_child_weight': 0.00018535534058839617, 'subsample': 0.8290034662998713, 'colsample_bytree': 0.8986457789066156, 'reg_alpha': 0.028032120695617477, 'reg_lambda': 0.0007875134729927658, 'learning_rate': 0.3022530490433629}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:08:52,922] Trial 42 finished with value: 0.7805825242718447 and parameters: {'max_depth': 8, 'min_child_weight': 0.0006550273402545929, 'subsample': 0.7801916274763305, 'colsample_bytree': 0.8587044694742733, 'reg_alpha': 0.007225094321281062, 'reg_lambda': 0.000486127007948824, 'learning_rate': 0.20782905010210315}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:08:59,119] Trial 43 finished with value: 0.7650485436893204 and parameters: {'max_depth': 9, 'min_child_weight': 0.0002507391220388546, 'subsample': 0.8061200140800424, 'colsample_bytree': 0.9188277132647376, 'reg_alpha': 0.18864455452584208, 'reg_lambda': 0.0003069237902885102, 'learning_rate': 0.3692188691808555}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:09:04,004] Trial 44 finished with value: 0.7582524271844661 and parameters: {'max_depth': 7, 'min_child_weight': 0.0023672602258224583, 'subsample': 0.708607989436356, 'colsample_bytree': 0.8905225082500843, 'reg_alpha': 0.05350696012678577, 'reg_lambda': 0.0006682819341637953, 'learning_rate': 0.12918409556658514}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:09:08,840] Trial 45 finished with value: 0.7456310679611651 and parameters: {'max_depth': 8, 'min_child_weight': 2.8445530953853485e-05, 'subsample': 0.750296360295839, 'colsample_bytree': 0.9726079049675216, 'reg_alpha': 0.4362148323306737, 'reg_lambda': 0.007015039352371875, 'learning_rate': 0.47618008047803695}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:09:17,943] Trial 46 finished with value: 0.7941747572815534 and parameters: {'max_depth': 9, 'min_child_weight': 0.0006580936573316779, 'subsample': 0.9968552066931784, 'colsample_bytree': 0.9324092694113479, 'reg_alpha': 0.12425627590642453, 'reg_lambda': 0.0026233236929008395, 'learning_rate': 0.17295332782043754}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:09:28,597] Trial 47 finished with value: 0.7825242718446602 and parameters: {'max_depth': 10, 'min_child_weight': 0.0007599783058659496, 'subsample': 0.9127424077635287, 'colsample_bytree': 0.9442805655151921, 'reg_alpha': 0.17121336467093845, 'reg_lambda': 0.002693422751229809, 'learning_rate': 0.16447329262983518}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:09:37,931] Trial 48 finished with value: 0.7902912621359224 and parameters: {'max_depth': 9, 'min_child_weight': 0.001755907502020706, 'subsample': 0.9911068961502425, 'colsample_bytree': 0.8608605616889476, 'reg_alpha': 0.11553759689194973, 'reg_lambda': 0.0008544914552606651, 'learning_rate': 0.13699243058479224}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:09:41,331] Trial 49 finished with value: 0.7699029126213592 and parameters: {'max_depth': 9, 'min_child_weight': 0.0005182081050613836, 'subsample': 0.9405029256774726, 'colsample_bytree': 0.9310654900859102, 'reg_alpha': 0.386952415215382, 'reg_lambda': 0.004620676138216731, 'learning_rate': 0.79146169182302}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:09:47,193] Trial 50 finished with value: 0.7669902912621359 and parameters: {'max_depth': 10, 'min_child_weight': 9.559570819656489e-05, 'subsample': 0.6742587694849588, 'colsample_bytree': 0.8376761934015298, 'reg_alpha': 0.06369329450602737, 'reg_lambda': 0.0022333131542523177, 'learning_rate': 0.5082521379014191}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:09:56,144] Trial 51 finished with value: 0.7815533980582524 and parameters: {'max_depth': 9, 'min_child_weight': 0.0015293872630025855, 'subsample': 0.9825548287313528, 'colsample_bytree': 0.8618057852334302, 'reg_alpha': 0.12196878100902439, 'reg_lambda': 0.0008024336980001458, 'learning_rate': 0.12984272708725209}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:10:04,261] Trial 52 finished with value: 0.7893203883495146 and parameters: {'max_depth': 10, 'min_child_weight': 0.0038054178877068114, 'subsample': 0.9971436420200754, 'colsample_bytree': 0.8856135373885371, 'reg_alpha': 0.1745748214855764, 'reg_lambda': 0.0011006814079055954, 'learning_rate': 0.28114682771202515}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:10:13,928] Trial 53 finished with value: 0.7912621359223301 and parameters: {'max_depth': 9, 'min_child_weight': 0.00026059403446825193, 'subsample': 0.9390696327495095, 'colsample_bytree': 0.9159978483834186, 'reg_alpha': 0.07967049397974746, 'reg_lambda': 0.002088674778420412, 'learning_rate': 0.17031591359804932}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:10:23,932] Trial 54 finished with value: 0.7834951456310679 and parameters: {'max_depth': 9, 'min_child_weight': 0.0003755871355662202, 'subsample': 0.9780566772721226, 'colsample_bytree': 0.9553993980822679, 'reg_alpha': 0.028283083282097027, 'reg_lambda': 0.0015766788735682242, 'learning_rate': 0.19031055971552058}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:10:29,784] Trial 55 finished with value: 0.7864077669902912 and parameters: {'max_depth': 8, 'min_child_weight': 0.00010514279680772789, 'subsample': 0.9306503910656881, 'colsample_bytree': 0.9222934665364534, 'reg_alpha': 0.07129011470356189, 'reg_lambda': 0.0034439171000202966, 'learning_rate': 0.3983388908258044}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:10:35,567] Trial 56 finished with value: 0.7699029126213592 and parameters: {'max_depth': 9, 'min_child_weight': 0.00025946793711903964, 'subsample': 0.9624186685538522, 'colsample_bytree': 0.9853688412567841, 'reg_alpha': 0.33946412370695633, 'reg_lambda': 0.002376432685156252, 'learning_rate': 0.3691048002766344}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:10:47,057] Trial 57 finished with value: 0.7893203883495146 and parameters: {'max_depth': 10, 'min_child_weight': 4.697357272054913e-05, 'subsample': 0.9582921976877041, 'colsample_bytree': 0.9029001370246021, 'reg_alpha': 0.034831801970734114, 'reg_lambda': 0.008285928604499523, 'learning_rate': 0.2212937647064009}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:10:54,851] Trial 58 finished with value: 0.7708737864077669 and parameters: {'max_depth': 8, 'min_child_weight': 0.000871730636495757, 'subsample': 0.8839241796152124, 'colsample_bytree': 0.939452247933266, 'reg_alpha': 0.07665702985076436, 'reg_lambda': 0.0015867502278066896, 'learning_rate': 0.09753061127092658}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:11:05,104] Trial 59 finished with value: 0.7980582524271844 and parameters: {'max_depth': 9, 'min_child_weight': 1.77283345706444e-05, 'subsample': 0.8751075407708331, 'colsample_bytree': 0.9622717248319682, 'reg_alpha': 0.008697378061527832, 'reg_lambda': 0.004907050888613929, 'learning_rate': 0.16314906077332642}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:11:12,972] Trial 60 finished with value: 0.7864077669902912 and parameters: {'max_depth': 8, 'min_child_weight': 1.7424710643080543e-05, 'subsample': 0.8692083264769299, 'colsample_bytree': 0.9615400458013156, 'reg_alpha': 0.008297615562706003, 'reg_lambda': 0.013611780650761981, 'learning_rate': 0.3177605725005295}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:11:22,601] Trial 61 finished with value: 0.7825242718446602 and parameters: {'max_depth': 9, 'min_child_weight': 1.911322522493389e-05, 'subsample': 0.7952311159418506, 'colsample_bytree': 0.9758033341693119, 'reg_alpha': 0.020523162702351924, 'reg_lambda': 0.004810755556478589, 'learning_rate': 0.16054648239564112}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:11:31,461] Trial 62 finished with value: 0.7961165048543689 and parameters: {'max_depth': 9, 'min_child_weight': 4.2883360411997545e-05, 'subsample': 0.9404144469372265, 'colsample_bytree': 0.9228461502283586, 'reg_alpha': 0.010269851351405936, 'reg_lambda': 0.007340858321506247, 'learning_rate': 0.2730100751578264}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:11:42,744] Trial 63 finished with value: 0.7844660194174757 and parameters: {'max_depth': 10, 'min_child_weight': 4.0229977287180066e-05, 'subsample': 0.7675280596885615, 'colsample_bytree': 0.9405904605273641, 'reg_alpha': 0.004745639770952567, 'reg_lambda': 0.006994691158294593, 'learning_rate': 0.29317195227339304}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:11:48,968] Trial 64 finished with value: 0.7864077669902912 and parameters: {'max_depth': 9, 'min_child_weight': 0.0001128354618218718, 'subsample': 0.8554888087980861, 'colsample_bytree': 0.8849379581695097, 'reg_alpha': 0.012424523492159967, 'reg_lambda': 0.01059330672422488, 'learning_rate': 0.5199003878204336}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:11:55,840] Trial 65 finished with value: 0.7708737864077669 and parameters: {'max_depth': 8, 'min_child_weight': 5.985605768917566e-05, 'subsample': 0.7322978174184103, 'colsample_bytree': 0.926961607790766, 'reg_alpha': 0.007002780099862489, 'reg_lambda': 0.035493688623218854, 'learning_rate': 0.22584262229907054}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:11:59,851] Trial 66 finished with value: 0.7669902912621359 and parameters: {'max_depth': 7, 'min_child_weight': 1.1177569092192121e-05, 'subsample': 0.7813297917535053, 'colsample_bytree': 0.9532344795477704, 'reg_alpha': 0.01846528190368377, 'reg_lambda': 0.0032252931058623585, 'learning_rate': 0.7447733773454227}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:12:11,851] Trial 67 finished with value: 0.7932038834951456 and parameters: {'max_depth': 10, 'min_child_weight': 2.7181341860893058e-05, 'subsample': 0.8198743972593895, 'colsample_bytree': 0.9757331368255318, 'reg_alpha': 0.0032968981861367748, 'reg_lambda': 0.0160126127047836, 'learning_rate': 0.2594066115023036}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:12:23,099] Trial 68 finished with value: 0.7805825242718447 and parameters: {'max_depth': 10, 'min_child_weight': 2.1386391946667933e-05, 'subsample': 0.8137563098321797, 'colsample_bytree': 0.9854498172879119, 'reg_alpha': 0.0027108654421810962, 'reg_lambda': 0.03317558723861888, 'learning_rate': 0.4168282600411235}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:12:36,014] Trial 69 finished with value: 0.7922330097087379 and parameters: {'max_depth': 10, 'min_child_weight': 1.605140725622397e-05, 'subsample': 0.8389955387673488, 'colsample_bytree': 0.9659662225875514, 'reg_alpha': 0.0017136986900543115, 'reg_lambda': 0.012522233149724225, 'learning_rate': 0.26079458133565114}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:12:47,503] Trial 70 finished with value: 0.7825242718446602 and parameters: {'max_depth': 10, 'min_child_weight': 2.923688575807073e-05, 'subsample': 0.8698327543644717, 'colsample_bytree': 0.9973076797077003, 'reg_alpha': 0.010062615878223784, 'reg_lambda': 0.016180384630985672, 'learning_rate': 0.06841245840591587}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:12:59,288] Trial 71 finished with value: 0.7883495145631068 and parameters: {'max_depth': 10, 'min_child_weight': 1.3061978618998508e-05, 'subsample': 0.8292937000027796, 'colsample_bytree': 0.964772840264248, 'reg_alpha': 0.0017760414555595511, 'reg_lambda': 0.009453735104637815, 'learning_rate': 0.2683959435804135}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:13:12,013] Trial 72 finished with value: 0.7961165048543689 and parameters: {'max_depth': 10, 'min_child_weight': 4.117029896520928e-05, 'subsample': 0.9018522071309727, 'colsample_bytree': 0.9773727866559522, 'reg_alpha': 0.0038125191281775683, 'reg_lambda': 0.017114877497605274, 'learning_rate': 0.23591709881253622}. Best is trial 34 with value: 0.7980582524271844.\n",
      "[I 2023-11-11 16:13:23,841] Trial 73 finished with value: 0.8 and parameters: {'max_depth': 10, 'min_child_weight': 6.241686788970666e-05, 'subsample': 0.8881035075063528, 'colsample_bytree': 0.9473652219754443, 'reg_alpha': 0.003647775475541457, 'reg_lambda': 0.005083154104687895, 'learning_rate': 0.18126248536760736}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:13:35,901] Trial 74 finished with value: 0.7883495145631068 and parameters: {'max_depth': 10, 'min_child_weight': 8.005262987703388e-05, 'subsample': 0.9015395034336879, 'colsample_bytree': 0.9798566221790771, 'reg_alpha': 0.004081659126651177, 'reg_lambda': 0.0061719443350525165, 'learning_rate': 0.15262998400491387}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:13:48,430] Trial 75 finished with value: 0.7912621359223301 and parameters: {'max_depth': 10, 'min_child_weight': 0.00013581006069625143, 'subsample': 0.8802319125227263, 'colsample_bytree': 0.9506579158062264, 'reg_alpha': 0.0011281324090286426, 'reg_lambda': 0.021160318883658925, 'learning_rate': 0.1789767989297123}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:14:00,923] Trial 76 finished with value: 0.7902912621359224 and parameters: {'max_depth': 10, 'min_child_weight': 4.1133235603461796e-05, 'subsample': 0.9220015626017958, 'colsample_bytree': 0.9275709456940631, 'reg_alpha': 0.00575225660307632, 'reg_lambda': 0.009714203635580803, 'learning_rate': 0.11221878407894767}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:14:12,020] Trial 77 finished with value: 0.7883495145631068 and parameters: {'max_depth': 9, 'min_child_weight': 5.243814853040596e-05, 'subsample': 0.8965280929634267, 'colsample_bytree': 0.9813800634540534, 'reg_alpha': 0.003729309689889412, 'reg_lambda': 0.004356514118671671, 'learning_rate': 0.2060761046007263}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:14:21,289] Trial 78 finished with value: 0.7893203883495146 and parameters: {'max_depth': 9, 'min_child_weight': 0.00014224893725731292, 'subsample': 0.9474953830072252, 'colsample_bytree': 0.91238238209733, 'reg_alpha': 0.000746920231251551, 'reg_lambda': 0.017165851700612786, 'learning_rate': 0.1377486705097255}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:14:33,937] Trial 79 finished with value: 0.7873786407766991 and parameters: {'max_depth': 10, 'min_child_weight': 7.435356343846434e-05, 'subsample': 0.914029162014761, 'colsample_bytree': 0.943374438031347, 'reg_alpha': 0.002465488778155674, 'reg_lambda': 0.08098735225920753, 'learning_rate': 0.23600967474550003}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:14:36,541] Trial 80 finished with value: 0.7281553398058253 and parameters: {'max_depth': 5, 'min_child_weight': 0.00039487207164011165, 'subsample': 0.9255527307502635, 'colsample_bytree': 0.9995702460813458, 'reg_alpha': 0.005979427888514884, 'reg_lambda': 0.003971601422741989, 'learning_rate': 0.11422584020594642}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:14:45,024] Trial 81 finished with value: 0.7883495145631068 and parameters: {'max_depth': 9, 'min_child_weight': 2.779328309365539e-05, 'subsample': 0.8445559026494647, 'colsample_bytree': 0.9032739277983997, 'reg_alpha': 0.009382856253598809, 'reg_lambda': 0.005824956857270451, 'learning_rate': 0.31408462511904417}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:14:52,732] Trial 82 finished with value: 0.7922330097087379 and parameters: {'max_depth': 10, 'min_child_weight': 3.6223073924631636e-05, 'subsample': 0.9756570544273941, 'colsample_bytree': 0.9586848702523989, 'reg_alpha': 0.012359204165961939, 'reg_lambda': 0.0027844635029082446, 'learning_rate': 0.4064329906447953}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:15:02,203] Trial 83 finished with value: 0.7951456310679612 and parameters: {'max_depth': 9, 'min_child_weight': 1.9000717699669234e-05, 'subsample': 0.8579993537055092, 'colsample_bytree': 0.9331266312096508, 'reg_alpha': 0.0048459159167929715, 'reg_lambda': 0.008675235689787002, 'learning_rate': 0.32150934842487455}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:15:12,116] Trial 84 finished with value: 0.7961165048543689 and parameters: {'max_depth': 9, 'min_child_weight': 6.19701486212774e-05, 'subsample': 0.8897774951912978, 'colsample_bytree': 0.9699973118524491, 'reg_alpha': 0.003979443940488014, 'reg_lambda': 0.0076636896334509414, 'learning_rate': 0.18775388434874588}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:15:21,604] Trial 85 finished with value: 0.7844660194174757 and parameters: {'max_depth': 9, 'min_child_weight': 6.347630528873539e-05, 'subsample': 0.8976836343394682, 'colsample_bytree': 0.9318516157602974, 'reg_alpha': 0.004832380411493801, 'reg_lambda': 0.006995105327957329, 'learning_rate': 0.18923630916937015}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:15:30,595] Trial 86 finished with value: 0.7893203883495146 and parameters: {'max_depth': 9, 'min_child_weight': 0.00015890636906622514, 'subsample': 0.8604772946850049, 'colsample_bytree': 0.9457946952051021, 'reg_alpha': 0.006530715632119759, 'reg_lambda': 0.010760452420981783, 'learning_rate': 0.3071438672489703}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:15:40,070] Trial 87 finished with value: 0.7902912621359224 and parameters: {'max_depth': 9, 'min_child_weight': 0.00020770429717827175, 'subsample': 0.886570816173594, 'colsample_bytree': 0.9128860787466676, 'reg_alpha': 0.002122757479296746, 'reg_lambda': 0.005854570152976529, 'learning_rate': 0.15910233876653568}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:15:41,289] Trial 88 finished with value: 0.6786407766990291 and parameters: {'max_depth': 3, 'min_child_weight': 1.6720753667270562e-05, 'subsample': 0.8705390766285507, 'colsample_bytree': 0.8939153415877442, 'reg_alpha': 0.004045148368273622, 'reg_lambda': 0.0036233124581334223, 'learning_rate': 0.21388404917106824}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:15:50,713] Trial 89 finished with value: 0.7864077669902912 and parameters: {'max_depth': 9, 'min_child_weight': 9.640412177818696e-05, 'subsample': 0.8400061541838946, 'colsample_bytree': 0.9243967554832323, 'reg_alpha': 0.001356796831010592, 'reg_lambda': 0.0020945653280696397, 'learning_rate': 0.34456711729715445}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:15:59,811] Trial 90 finished with value: 0.7815533980582524 and parameters: {'max_depth': 9, 'min_child_weight': 1.0380050207347922e-05, 'subsample': 0.9100981795821631, 'colsample_bytree': 0.9670254294180826, 'reg_alpha': 0.002804137213230973, 'reg_lambda': 0.00131053448470684, 'learning_rate': 0.14063432900573242}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:16:12,064] Trial 91 finished with value: 0.7834951456310679 and parameters: {'max_depth': 10, 'min_child_weight': 3.172440773754702e-05, 'subsample': 0.8631415903501296, 'colsample_bytree': 0.9789017596538784, 'reg_alpha': 0.0033641248645853903, 'reg_lambda': 0.013298722909736023, 'learning_rate': 0.2494990350720505}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:16:24,401] Trial 92 finished with value: 0.7893203883495146 and parameters: {'max_depth': 10, 'min_child_weight': 2.2592967859591866e-05, 'subsample': 0.8825566614595252, 'colsample_bytree': 0.9488099036358071, 'reg_alpha': 0.002206925439640912, 'reg_lambda': 0.020517366329728937, 'learning_rate': 0.18419050997915581}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:16:26,197] Trial 93 finished with value: 0.7320388349514563 and parameters: {'max_depth': 4, 'min_child_weight': 5.7889004748595574e-05, 'subsample': 0.8450762837759784, 'colsample_bytree': 0.9710600510476908, 'reg_alpha': 0.0033539258134226476, 'reg_lambda': 0.007441994032501472, 'learning_rate': 0.2709833691034403}. Best is trial 73 with value: 0.8.\n",
      "[I 2023-11-11 16:16:35,609] Trial 94 finished with value: 0.8048543689320389 and parameters: {'max_depth': 9, 'min_child_weight': 3.695923764149081e-05, 'subsample': 0.8542269678074701, 'colsample_bytree': 0.9354653813296343, 'reg_alpha': 0.008222462790243272, 'reg_lambda': 0.005007233372788533, 'learning_rate': 0.23110792970871943}. Best is trial 94 with value: 0.8048543689320389.\n",
      "[I 2023-11-11 16:16:44,982] Trial 95 finished with value: 0.7902912621359224 and parameters: {'max_depth': 9, 'min_child_weight': 4.5082064607814724e-05, 'subsample': 0.8578961542407366, 'colsample_bytree': 0.9564445893802376, 'reg_alpha': 0.019119339112351023, 'reg_lambda': 0.004306242210738271, 'learning_rate': 0.21912360169760153}. Best is trial 94 with value: 0.8048543689320389.\n",
      "[I 2023-11-11 16:16:52,955] Trial 96 finished with value: 0.7961165048543689 and parameters: {'max_depth': 9, 'min_child_weight': 0.00010946440583702801, 'subsample': 0.9086437690902167, 'colsample_bytree': 0.9381934641635561, 'reg_alpha': 0.010261217377294792, 'reg_lambda': 0.0027451200823614937, 'learning_rate': 0.3541208620811161}. Best is trial 94 with value: 0.8048543689320389.\n",
      "[I 2023-11-11 16:16:59,040] Trial 97 finished with value: 0.7912621359223301 and parameters: {'max_depth': 9, 'min_child_weight': 0.00011175250397235478, 'subsample': 0.889768913123124, 'colsample_bytree': 0.9374944832630411, 'reg_alpha': 0.008595933966669609, 'reg_lambda': 0.0018047277401189955, 'learning_rate': 0.5411457692799814}. Best is trial 94 with value: 0.8048543689320389.\n",
      "[I 2023-11-11 16:17:05,860] Trial 98 finished with value: 0.7815533980582524 and parameters: {'max_depth': 9, 'min_child_weight': 0.00026417554830186627, 'subsample': 0.8737546411868357, 'colsample_bytree': 0.8757009232309655, 'reg_alpha': 0.012218055660252579, 'reg_lambda': 0.009028683373456492, 'learning_rate': 0.43278085160694796}. Best is trial 94 with value: 0.8048543689320389.\n",
      "[I 2023-11-11 16:17:13,282] Trial 99 finished with value: 0.7844660194174757 and parameters: {'max_depth': 8, 'min_child_weight': 8.199028446653876e-05, 'subsample': 0.9025436083502305, 'colsample_bytree': 0.918606096531472, 'reg_alpha': 0.005400868413529137, 'reg_lambda': 0.005218670722889516, 'learning_rate': 0.36168061070426377}. Best is trial 94 with value: 0.8048543689320389.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       511\n",
      "           1       0.75      0.78      0.77       358\n",
      "           2       0.83      0.59      0.69       151\n",
      "           3       1.00      0.40      0.57        10\n",
      "\n",
      "    accuracy                           0.80      1030\n",
      "   macro avg       0.85      0.67      0.72      1030\n",
      "weighted avg       0.81      0.80      0.80      1030\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred, results = xgb_op(**data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-12 20:17:55,164] A new study created in memory with name: no-name-1392a948-c3cc-4839-a6c2-34d0c5fa7d13\n",
      "[W 2023-11-12 20:18:02,192] Trial 0 failed with parameters: {'max_depth': 8, 'min_child_weight': 12.596146112275592, 'subsample': 0.8011498986622121, 'colsample_bytree': 0.764856456202504, 'reg_alpha': 4.88103378266294, 'reg_lambda': 0.5885353390552773, 'learning_rate': 0.8015268664784329} because of the following error: ValueError(\"Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\").\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Zoe Lua\\AppData\\Local\\Temp\\ipykernel_11948\\279656975.py\", line 129, in xgb_trial\n",
      "    results = evaluate(y_test, pred)\n",
      "  File \"C:\\Users\\Zoe Lua\\AppData\\Local\\Temp\\ipykernel_11948\\279656975.py\", line 16, in evaluate\n",
      "    'f2_score': f2_score(y_test, y_pred)\n",
      "  File \"C:\\Users\\Zoe Lua\\AppData\\Local\\Temp\\ipykernel_11948\\279656975.py\", line 2, in f2_score\n",
      "    precision = precision_score(y_true, y_pred)\n",
      "  File \"c:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 2127, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 184, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1721, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1516, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "[W 2023-11-12 20:18:02,196] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Zoe Lua\\Documents\\School\\Education\\Y4S1\\alzheimer_detection-1\\xgboost_glcm.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_pred, results \u001b[39m=\u001b[39m xgb_op(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdata, metric \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf2_score\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Zoe Lua\\Documents\\School\\Education\\Y4S1\\alzheimer_detection-1\\xgboost_glcm.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results[metric]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(xgb_trial, n_trials \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m model \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_trial\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m model_copy \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(model)\n",
      "File \u001b[1;32mc:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32mc:\\Users\\Zoe Lua\\Documents\\School\\Education\\Y4S1\\alzheimer_detection-1\\xgboost_glcm.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=128'>129</a>\u001b[0m results \u001b[39m=\u001b[39m evaluate(y_test, pred)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=130'>131</a>\u001b[0m \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m     \u001b[39mprint\u001b[39m(classification_report(y_test, pred))\n",
      "\u001b[1;32mc:\\Users\\Zoe Lua\\Documents\\School\\Education\\Y4S1\\alzheimer_detection-1\\xgboost_glcm.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(y_test, y_pred):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     results \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m: recall_score(y_test, y_pred, average \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m: precision_score(y_test, y_pred, average \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m: accuracy_score(y_test, y_pred),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mf1_score\u001b[39m\u001b[39m'\u001b[39m: f1_score(y_test, y_pred, average \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmcc\u001b[39m\u001b[39m'\u001b[39m: matthews_corrcoef(y_test, y_pred),\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mf2_score\u001b[39m\u001b[39m'\u001b[39m: f2_score(y_test, y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "\u001b[1;32mc:\\Users\\Zoe Lua\\Documents\\School\\Education\\Y4S1\\alzheimer_detection-1\\xgboost_glcm.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf2_score\u001b[39m(y_true, y_pred, beta\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     precision \u001b[39m=\u001b[39m precision_score(y_true, y_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     recall \u001b[39m=\u001b[39m recall_score(y_true, y_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Zoe%20Lua/Documents/School/Education/Y4S1/alzheimer_detection-1/xgboost_glcm.ipynb#X54sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     f2 \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m beta\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m (precision \u001b[39m*\u001b[39m recall) \u001b[39m/\u001b[39m ((beta\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m precision) \u001b[39m+\u001b[39m recall)\n",
      "File \u001b[1;32mc:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2127\u001b[0m, in \u001b[0;36mprecision_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1970\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m   1971\u001b[0m     {\n\u001b[0;32m   1972\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1996\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1997\u001b[0m ):\n\u001b[0;32m   1998\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[0;32m   1999\u001b[0m \n\u001b[0;32m   2000\u001b[0m \u001b[39m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2125\u001b[0m \u001b[39m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[0;32m   2126\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2127\u001b[0m     p, _, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m   2128\u001b[0m         y_true,\n\u001b[0;32m   2129\u001b[0m         y_pred,\n\u001b[0;32m   2130\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   2131\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m   2132\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[0;32m   2133\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[0;32m   2134\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   2135\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[0;32m   2136\u001b[0m     )\n\u001b[0;32m   2137\u001b[0m     \u001b[39mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[0;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1721\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1563\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m \n\u001b[0;32m   1565\u001b[0m \u001b[39mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[39m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m zero_division_value \u001b[39m=\u001b[39m _check_zero_division(zero_division)\n\u001b[1;32m-> 1721\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m   1723\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Zoe Lua\\anaconda3\\envs\\dsaEnv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1516\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1514\u001b[0m         \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1515\u001b[0m             average_options\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1516\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1517\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTarget is \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m but average=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. Please \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1518\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mchoose another average setting, one of \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1519\u001b[0m         )\n\u001b[0;32m   1520\u001b[0m \u001b[39melif\u001b[39;00m pos_label \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m):\n\u001b[0;32m   1521\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1522\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNote that pos_label (set to \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) is ignored when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1523\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maverage != \u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m). You may use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1526\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[0;32m   1527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "y_pred, results = xgb_op(**data, metric = \"f2_score\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
